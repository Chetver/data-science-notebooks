{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Machine-Learning\" data-toc-modified-id=\"Machine-Learning-1\">Machine Learning</a></span></li><li><span><a href=\"#Four-Step-Approach\" data-toc-modified-id=\"Four-Step-Approach-2\">Four Step Approach</a></span><ul class=\"toc-item\"><li><span><a href=\"#Linear-Model\" data-toc-modified-id=\"Linear-Model-2.1\">Linear Model</a></span></li></ul></li><li><span><a href=\"#Objective-Function\" data-toc-modified-id=\"Objective-Function-3\">Objective Function</a></span><ul class=\"toc-item\"><li><span><a href=\"#Two-Types-of-Objective-Function\" data-toc-modified-id=\"Two-Types-of-Objective-Function-3.1\">Two Types of Objective Function</a></span></li></ul></li><li><span><a href=\"#Loss-Functions\" data-toc-modified-id=\"Loss-Functions-4\">Loss Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Two-Types-of-Loss-Function:\" data-toc-modified-id=\"The-Two-Types-of-Loss-Function:-4.1\">The Two Types of Loss Function:</a></span></li><li><span><a href=\"#L2-Norm\" data-toc-modified-id=\"L2-Norm-4.2\">L2-Norm</a></span></li><li><span><a href=\"#Cross-Entropy\" data-toc-modified-id=\"Cross-Entropy-4.3\">Cross-Entropy</a></span></li></ul></li><li><span><a href=\"#Optimization-Algorithm\" data-toc-modified-id=\"Optimization-Algorithm-5\">Optimization Algorithm</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gradiant-Descent\" data-toc-modified-id=\"Gradiant-Descent-5.1\">Gradiant Descent</a></span></li><li><span><a href=\"#Update-Rule\" data-toc-modified-id=\"Update-Rule-5.2\">Update Rule</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## Machine Learning\n",
    "- Supervised\n",
    "    - Classification\n",
    "        - Logistic Regression\n",
    "        - KNN\n",
    "    - Regression\n",
    "        - Linear Regression\n",
    "- Unsupervised\n",
    "    - Kmeans\n",
    "- Re-inforced\n",
    "\n",
    "Algorithm decided by you after checking the requirement.\n",
    "\n",
    "Deep learning - The algorithm used is not known.\n",
    "\n",
    "If you don't know what the output should be -> use KMeans\n",
    "\n",
    "If you know what the output will be -> KNN\n",
    "\n",
    "Real Life Scenarios:\n",
    "Linear + Non-Linear\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Step Approach\n",
    "1. Data\n",
    "2. Model\n",
    "3. Objective Function\n",
    "    - Minimize Error in Prediction\n",
    "    - Iterative Process\n",
    "4. Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model\n",
    "\n",
    "$y=wx+b$\n",
    "\n",
    "## Objective Function\n",
    "The measure used to evaluate how well the models output matches the desired correct values.\n",
    "\n",
    "### Two Types of Objective Function\n",
    "1. Loss\n",
    "    - Always want to minimise loss.\n",
    "    - The lower the loss function the higher the acuracy.\n",
    "    - Loss functions are used in supervised machine learning.\n",
    "2. Reward\n",
    "    - The higher the reward function, the higher the asccuracy\n",
    "    - Reward functions are used in re-inforced machine learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "### The Two Types of Loss Function:\n",
    "1. L2-Norm (Means Squared Error)\n",
    "    - Used when problem is to be solved via Regression\n",
    "2. Cross Entropy \n",
    "    - Used when problem is to be solved via Classification\n",
    "    \n",
    "### L2-Norm\n",
    "$\\sum_i(y_i-t_i)^2\\\\\n",
    "\\text{Where:}\\\\\n",
    "y = \\text{prediticed output}\\\\\n",
    "t = \\text{target (actual output)}\n",
    "$\n",
    "### Cross-Entropy\n",
    "$L(y,t) = \\sum_i t_i \\log y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Algorithm\n",
    "\n",
    "For a linear Algorithm, the optimisation algorithm varies the weights and bias.\n",
    "\n",
    "### Gradiant Descent\n",
    "\n",
    "$f(x) = 5x^2 + 3x - 4$\n",
    "\n",
    "$x_{i+1} = x_i - \\eta f(x_i)$\n",
    "\n",
    "*Note: $\\eta$ is the symbol \"eta\" and in TeX is ```\\eta```*\n",
    "\n",
    "Where $\\eta$ is the **Learning Rate**.\n",
    "1. $f(x) = 10x+3$\n",
    "2. Update Rate:  \n",
    "    $x_0 = 4$  \n",
    "    $x_1 = x_0 - \\eta f(x_0)$  \n",
    "    $x_2 = x_1 - \\eta f(x_1)$\n",
    "    \n",
    "When $x_{i+1} = x_i$ The optimisation algorithm has achieved minimum loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Rule\n",
    "\n",
    "$x_{i+1} = x_i \\eta f(x_i)$  \n",
    "$ w_{i+1} = w_i - \\eta \\nabla_w L(y,t)$  \n",
    "$\\beta_{i+1} = \\beta_i - \\eta \\nabla_\\beta L(y,t)$\n",
    "\n",
    "$\\text{dt}_w L=\\sum_i x_i \\delta_i$  \n",
    "$\\delta_i = y_i - t_i$  \n",
    "$\\nabla_\\beta L = \\sum_i \\delta_i$\n",
    "\n",
    "$$W_{i+1} = W_i - \\eta \\sum_i x_i \\delta_i$$"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
