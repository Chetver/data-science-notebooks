{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('1.01. Simple linear regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT   GPA\n",
       "0  1714  2.40\n",
       "1  1664  2.52\n",
       "2  1760  2.54\n",
       "3  1685  2.74\n",
       "4  1693  2.83"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the regression model. GPA--dependent variable/feature. It is being predicted using SAT, which is an independent variable/feature\n",
    "x=data['SAT']\n",
    "y=data['GPA']\n",
    "#x is called input or feature\n",
    "#y is called output or target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of input and target. They are both vectors of length 84\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1714 1664 1760 1685 1693 1670 1764 1764 1792 1850 1735 1775 1735 1712\n 1773 1872 1755 1674 1842 1786 1761 1722 1663 1687 1974 1826 1787 1821\n 2020 1794 1769 1934 1775 1855 1880 1849 1808 1954 1777 1831 1865 1850\n 1966 1702 1990 1925 1824 1956 1857 1979 1802 1855 1907 1634 1879 1887\n 1730 1953 1781 1891 1964 1808 1893 2041 1893 1832 1850 1934 1861 1931\n 1933 1778 1975 1934 2021 2015 1997 2020 1843 1936 1810 1987 1962 2050].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d87a2f6ea8b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#fit the regression. NOte the order of mentioning x and y. here order is important. IN statsmodels it doesnt make any difference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#the above statement throws an error. Sklearn requires 2D array whereas we are providing 1-d array. YOu can see using the x.shape , that x is a vector and has a single dimension, length.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#we have to reshape it to a matrix.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 482\u001b[1;33m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1714 1664 1760 1685 1693 1670 1764 1764 1792 1850 1735 1775 1735 1712\n 1773 1872 1755 1674 1842 1786 1761 1722 1663 1687 1974 1826 1787 1821\n 2020 1794 1769 1934 1775 1855 1880 1849 1808 1954 1777 1831 1865 1850\n 1966 1702 1990 1925 1824 1956 1857 1979 1802 1855 1907 1634 1879 1887\n 1730 1953 1781 1891 1964 1808 1893 2041 1893 1832 1850 1934 1861 1931\n 1933 1778 1975 1934 2021 2015 1997 2020 1843 1936 1810 1987 1962 2050].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#sklearn makes very good use of the object oriented capability of Python\n",
    "#creating an instance of the LinearRegression class\n",
    "reg=LinearRegression()\n",
    "#fit the regression. NOte the order of mentioning x and y. here order is important. IN statsmodels it doesnt make any difference\n",
    "reg.fit(x,y)\n",
    "#the above statement throws an error. Sklearn requires 2D array whereas we are providing 1-d array. YOu can see using the x.shape , that x is a vector and has a single dimension, length.\n",
    "#we have to reshape it to a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping from 1-d array of length 84 to a 2-d array 84 cross 1\n",
    "x_matrix=x.values.reshape(84,1)\n",
    "#alternatively, we can use the suggestion from sklearn itself(observe the last few lines of the error obtained in the previous cell), i.e. use array.reshape(-1,1)\n",
    "x_matrix=x.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets run the regression with the reshaped feature\n",
    "reg.fit(x_matrix,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#focussing on the parameters of LinearRegression\n",
    "#Standardization--(x-mu)/sigma\n",
    "#Normalization--(x-mu)/L2-Norm of the inputs\n",
    "# http://www.chioka.in/differences-between-the-l1-norm-and-the-l2-norm-least-absolute-deviations-and-least-squares/\n",
    "# https://en.wikipedia.org/wiki/Feature_scaling\n",
    "\n",
    "#copy_x=True- copies the inputs before fitting them. Its a safety net against normalizations and other transformations that can be done by sklearn while creating an algorithm.Similar to creating copies of dataframe\n",
    "#fit_intercept=True- In statsmodels we had to manually add a constant. the fit_intercept parameter takes care precisely of that. If you dont want an intercept you can just set it to false\n",
    "#n_jobs=1--used to parallelize routines.1 refers to the number of CPU being used. If the data set is extremely big and you want to use the power of parallel processing you can mention the values as 2,3,4 or 5, provided you have more than 1 CPU available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40600391479679765"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting R-squared--use the method reg.score(x,y)--this returns the R-squared of a Linear Regression\n",
    "reg.score(x_matrix,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00165569])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to figure out the coefficients:\n",
    "reg.coef_\n",
    "#reg.coef_ returns an array of coefficients depending upon the number features used. Here we are just using SAT, so coeff of SAT is returned which is equal to 0.0017(round off value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.275040299660279"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#obtaining the intercept\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.15593751])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Predictions:\n",
    "#use reg.predict(new_inputs)--returns the predictions of the linear regression model for some new inputs\n",
    "reg.predict(1740)\n",
    "#so here we passed the SAT score and the model predicts the GPA score as 3.155, and also this result, is an array, because the predict method can take more than a single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT\n",
       "0  1740\n",
       "1  1780"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#passing dataframe to predict()\n",
    "new_data=pd.DataFrame([1740,1780],columns=['SAT'])\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.15593751, 3.22216503])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the regression line on the scatter plot obtained from the previous step\n",
    "plt.scatter(x,y)\n",
    "yhat=reg.coef_*x_matrix+reg.intercept_\n",
    "#yhat=0.0017*x + 0.2750\n",
    "# Plot the regression line against the independent variable (SAT)\n",
    "fig=plt.plot(x,yhat,lw=4,c='orange',label='regression line')\n",
    "plt.xlabel('SAT',fontsize=20)\n",
    "plt.ylabel('GPA',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('1.02. Multiple linear regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1714</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1664</td>\n",
       "      <td>2.52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1760</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1685</td>\n",
       "      <td>2.74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693</td>\n",
       "      <td>2.83</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT   GPA  Rand 1,2,3\n",
       "0  1714  2.40           1\n",
       "1  1664  2.52           3\n",
       "2  1760  2.54           3\n",
       "3  1685  2.74           3\n",
       "4  1693  2.83           2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "#2 input features--SAT and Rand 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1845.273810</td>\n",
       "      <td>3.330238</td>\n",
       "      <td>2.059524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.530661</td>\n",
       "      <td>0.271617</td>\n",
       "      <td>0.855192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1634.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1772.000000</td>\n",
       "      <td>3.190000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1846.000000</td>\n",
       "      <td>3.380000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1934.000000</td>\n",
       "      <td>3.502500</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2050.000000</td>\n",
       "      <td>3.810000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               SAT        GPA  Rand 1,2,3\n",
       "count    84.000000  84.000000   84.000000\n",
       "mean   1845.273810   3.330238    2.059524\n",
       "std     104.530661   0.271617    0.855192\n",
       "min    1634.000000   2.400000    1.000000\n",
       "25%    1772.000000   3.190000    1.000000\n",
       "50%    1846.000000   3.380000    2.000000\n",
       "75%    1934.000000   3.502500    3.000000\n",
       "max    2050.000000   3.810000    3.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we already know that SAT score is a good predictor of GPA. Rand1,2,3 randomly assigned 1,2 or 3 to the samples. Sample is the machine learning term for observations\n",
    "x=data[['SAT','Rand 1,2,3']]\n",
    "y=data['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x,y)\n",
    "#Notice that this runs without any error. sklearn is optimized for multiple inputs, so we are getting a 2-d array over here as compared to the previous one where we had to reshape the input feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00165354, -0.00826982])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29603261264909353"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the R-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40668119528142815"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the adjusted r-squared is a better explanation for the model. If we are using features with low or no explanatory powers, theR-square will increase. So the execessive usageof independent variables/features is penalized by making use of adjusted r-squared\n",
    "#there is no specific function which can be directly used for calculating adj r-squared so we create our own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formula for adjusted r-squared\n",
    "$R^2_{adj.} = 1 - (1-R^2)*\\frac{n-1}{n-p-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as per the formula, n= no of observations(84) and p=no of predictors(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39203134825134"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets try to create this adj r-squared measure on our own\n",
    "r2=reg.score(x,y)\n",
    "#n=84 so we will use n=x.shape[0] which will extract 84. similarly for p--x.shape[1]\n",
    "n=x.shape[0]\n",
    "p=x.shape[1]\n",
    "adjusted_r2=1-(1-r2)*(n-1)/(n-p-1)\n",
    "adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare it with the previous multiple linear regression with stastmodels example. the value for adj r-squared will be 0.392\n",
    "#so adjusted r-squared<r-squared. Thus one or more perdictors have little or no explanatory power.\n",
    "#so now we have to identify which one has no predictive power and thus remove it. This process of identifying features which have little or no predictive power is known as FEATURE SELECTION WITH F-REGRESSION\n",
    "#Feature Selection simplifies models\n",
    "#When we used statsmodels we identified the features using p-value. If a variable has p-value>0.05, we can disregard it\n",
    "#next lets try to find out the p-values using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn makes use of f_regression. F-regression creates simple linear regressions of each feature and the dependent variable\n",
    "#here we will have GPA vs SAT and GPA vs Rand 1,2,3. Then the method will calculate the F-stats for each of those regression and return the p-value.\n",
    "#If there were 50 features, 50 linear regressions will be created\n",
    "#For a simple linear regression, the p-value of the F-stats coincides with the p-value of the only independent variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([56.04804786,  0.17558437]), array([7.19951844e-11, 6.76291372e-01]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_regression(x,y)\n",
    "#in the output, the first array contains the F-stats for each regressions and the 2nd array consists of the corresponding p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.19951844e-11, 6.76291372e-01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values=f_regression(x,y)[1]\n",
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.676])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using round() to round to 3 decimal digits\n",
    "p_values.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if p-value is >0.05, we disregard the feature/variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 1st value refers to the 1st column of x(x=data(['SAT','Rand 1,2,3'])) and the 2nd refers to the second column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary=pd.DataFrame(['SAT','Rand 1,2,3'],columns=['Features'])\n",
    "#if we want to parameterize the above code we can go ahead and use this code:\n",
    "#pd.DataFrame(data=x.columns.values,columns=['Features'])\n",
    "#so instead of providing every feature name we just made use of x.columns.values. this saves time when have lot of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features\n",
       "0         SAT\n",
       "1  Rand 1,2,3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary['Coefficients']=reg.coef_\n",
    "reg_summary['p-values']=p_values.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coefficients</th>\n",
       "      <th>p-values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAT</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.008270</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features  Coefficients  p-values\n",
       "0         SAT      0.001654     0.000\n",
       "1  Rand 1,2,3     -0.008270     0.676"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common problem in working with numerical data is the difference in magnitudes.\n",
    "#An easy fix for this issue is standardization also known as feature scaling or normalization. We will stick to the terms standardization and feature scaling\n",
    "#Standardization/Feature Scaling-process of transforming the data we are working with into a standard scale.\n",
    "#Z=(x-mu)/sigma\n",
    "#Example if we have trading data having 2 columns, 'European Dollar Exchange Rate' and 'Daily trading volume' with the data for both colums as follow:\n",
    "# EDER    DailyTradingVolume\n",
    "# 1.3     110000\n",
    "# 1.34    98700\n",
    "# 1.25    135000\n",
    "#the scale is extremely different. So we go ahead and use the Standardizing variable Z, with mean and std deviation of each column\n",
    "#The standardized data set:\n",
    "# EDER    DailyTradingVolume\n",
    "# 0.07     -0.25\n",
    "# 0.96    -0.85\n",
    "# -1.03    1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data[['SAT','Rand 1,2,3']]\n",
    "y=data['GPA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use the StandardScaler() module(a preprocessing module used to standardize/scale data) from sklearn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "#the scaler object which we created just now, will be used to scale our data. In other words it will subtract the mean and divide by standard deviation from each feature point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the input data\n",
    "scaler.fit(x)\n",
    "#this line of code calculates the mean and standard deviation of each feature and stores them in the scaler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26338288, -1.24637147],\n",
       "       [-1.74458431,  1.10632974],\n",
       "       [-0.82067757,  1.10632974],\n",
       "       [-1.54247971,  1.10632974],\n",
       "       [-1.46548748, -0.07002087],\n",
       "       [-1.68684014, -1.24637147],\n",
       "       [-0.78218146, -0.07002087],\n",
       "       [-0.78218146, -1.24637147],\n",
       "       [-0.51270866, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [-1.06127829,  1.10632974],\n",
       "       [-0.67631715, -0.07002087],\n",
       "       [-1.06127829, -1.24637147],\n",
       "       [-1.28263094,  1.10632974],\n",
       "       [-0.6955652 , -0.07002087],\n",
       "       [ 0.25721362, -0.07002087],\n",
       "       [-0.86879772,  1.10632974],\n",
       "       [-1.64834403, -0.07002087],\n",
       "       [-0.03150724,  1.10632974],\n",
       "       [-0.57045283,  1.10632974],\n",
       "       [-0.81105355,  1.10632974],\n",
       "       [-1.18639066,  1.10632974],\n",
       "       [-1.75420834,  1.10632974],\n",
       "       [-1.52323165, -1.24637147],\n",
       "       [ 1.23886453, -1.24637147],\n",
       "       [-0.18549169, -1.24637147],\n",
       "       [-0.5608288 , -1.24637147],\n",
       "       [-0.23361183,  1.10632974],\n",
       "       [ 1.68156984, -1.24637147],\n",
       "       [-0.4934606 , -0.07002087],\n",
       "       [-0.73406132, -1.24637147],\n",
       "       [ 0.85390339, -1.24637147],\n",
       "       [-0.67631715, -1.24637147],\n",
       "       [ 0.09360513,  1.10632974],\n",
       "       [ 0.33420585, -0.07002087],\n",
       "       [ 0.03586096, -0.07002087],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 1.04638396,  1.10632974],\n",
       "       [-0.65706909,  1.10632974],\n",
       "       [-0.13737155, -0.07002087],\n",
       "       [ 0.18984542,  1.10632974],\n",
       "       [ 0.04548499, -1.24637147],\n",
       "       [ 1.1618723 ,  1.10632974],\n",
       "       [-1.37887123, -1.24637147],\n",
       "       [ 1.39284898, -1.24637147],\n",
       "       [ 0.76728713, -0.07002087],\n",
       "       [-0.20473975, -0.07002087],\n",
       "       [ 1.06563201, -1.24637147],\n",
       "       [ 0.11285319, -1.24637147],\n",
       "       [ 1.28698467,  1.10632974],\n",
       "       [-0.41646838,  1.10632974],\n",
       "       [ 0.09360513, -1.24637147],\n",
       "       [ 0.59405462, -0.07002087],\n",
       "       [-2.03330517, -0.07002087],\n",
       "       [ 0.32458182, -1.24637147],\n",
       "       [ 0.40157405, -1.24637147],\n",
       "       [-1.10939843, -0.07002087],\n",
       "       [ 1.03675993, -1.24637147],\n",
       "       [-0.61857297, -0.07002087],\n",
       "       [ 0.44007016, -0.07002087],\n",
       "       [ 1.14262424, -1.24637147],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 0.45931822,  1.10632974],\n",
       "       [ 1.88367444,  1.10632974],\n",
       "       [ 0.45931822, -1.24637147],\n",
       "       [-0.12774752, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [ 0.85390339, -0.07002087],\n",
       "       [ 0.15134931, -0.07002087],\n",
       "       [ 0.8250313 ,  1.10632974],\n",
       "       [ 0.84427936,  1.10632974],\n",
       "       [-0.64744506, -1.24637147],\n",
       "       [ 1.24848856, -1.24637147],\n",
       "       [ 0.85390339,  1.10632974],\n",
       "       [ 1.69119387,  1.10632974],\n",
       "       [ 1.6334497 ,  1.10632974],\n",
       "       [ 1.46021718, -1.24637147],\n",
       "       [ 1.68156984, -0.07002087],\n",
       "       [-0.02188321,  1.10632974],\n",
       "       [ 0.87315144,  1.10632974],\n",
       "       [-0.33947615, -1.24637147],\n",
       "       [ 1.3639769 ,  1.10632974],\n",
       "       [ 1.12337618, -1.24637147],\n",
       "       [ 1.97029069, -0.07002087]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we created the scaler object and it has mean and standard deviation of feacture. But the inputs are still unscaled. SO to transform the inputs we go ahead and use:\n",
    "#StandardScaler.transform(x)--transofrms the unscaled inputs using the information contained in the scaler object. This is where each feature point goes through scaling(subtract the mean and divide by std deviation)\n",
    "#whenever we get new data we can just go ahead and apply scaler.transform(new_data)\n",
    "x_scaled=scaler.transform(x)\n",
    "x_scaled\n",
    "#we get the scaled/standardized inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we did this scaling because SAT score was in the range 600 to 2400 and Rand 1,2,3 in the range 1-3\n",
    "#if all the features have the same magnitude allows us to compare their impact\n",
    "#Creating new Regression with the scaled inputs:\n",
    "reg=LinearRegression()\n",
    "reg.fit(x_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17181389, -0.00703007])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.330238095238095"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a summary table\n",
    "reg_summary=pd.DataFrame([['Intercept'],['SAT'],['Rand 1,2,3']],columns=['Features'])\n",
    "reg_summary['Weights']=reg.intercept_,reg.coef_[0],reg.coef_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAT</td>\n",
       "      <td>0.171814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.007030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features   Weights\n",
       "0   Intercept  3.330238\n",
       "1         SAT  0.171814\n",
       "2  Rand 1,2,3 -0.007030"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary\n",
    "#Weights is the ML term for standardized coefficients\n",
    "#The bigger the weight the bigger is the impact of the feature on the regression\n",
    "#Similarly in ML the intercept is called BIAS. Intercept is nothing but a number which adjusts the regression with some constant. However if we need ot adjust our regression with some bias then the regresssion is biased by that number\n",
    "#So go ahead and repeat the same code as above..just mention Bias instead of Intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_summary=pd.DataFrame([['Bias'],['SAT'],['Rand 1,2,3']],columns=['Features'])\n",
    "reg_summary['Weights']=reg.intercept_,reg.coef_[0],reg.coef_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bias</td>\n",
       "      <td>3.330238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAT</td>\n",
       "      <td>0.171814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rand 1,2,3</td>\n",
       "      <td>-0.007030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Features   Weights\n",
       "0        Bias  3.330238\n",
       "1         SAT  0.171814\n",
       "2  Rand 1,2,3 -0.007030"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the closer the weight is to 0 the smaller the implact and vice-versa. Observe that the weight of SAT is 0.17 which is much bigger than the weight of Rand 1,2,3\n",
    "#So Rand 1,2,3 barely contributes to the model. SO we can remove it or let it be\n",
    "#The worst performing features have a lower p value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predcitions with the standardized coefficients(Weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking random data here\n",
    "raw_data=pd.DataFrame(data=[[1700,2],[1800,1]],columns=['SAT','Rand 1,2,3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SAT</th>\n",
       "      <th>Rand 1,2,3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SAT  Rand 1,2,3\n",
       "0  1700           2\n",
       "1  1800           1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([295.39979563, 312.58821497])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the predict method and pass the new input as arguments\n",
    "reg.predict(raw_data)\n",
    "#the output is quite confusing. 312 is not a valid GPA!This happened because our model was trained on standardized inputs. Here we have provided inputs which are not standadrized.Observe the scale difference between SAT and Rand 1,2,3 values\n",
    "#Our model expects values that are of the same magnitude like the ones used in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the new dataframe--raw_data, must be prepared and standardized in the same way as the input X, with the same mean and std deviation\n",
    "#the mean and standard deviation is stored in the scaler object\n",
    "new_data_scaled=scaler.transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.39811928, -0.07002087],\n",
       "       [-0.43571643, -1.24637147]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.26338288, -1.24637147],\n",
       "       [-1.74458431,  1.10632974],\n",
       "       [-0.82067757,  1.10632974],\n",
       "       [-1.54247971,  1.10632974],\n",
       "       [-1.46548748, -0.07002087],\n",
       "       [-1.68684014, -1.24637147],\n",
       "       [-0.78218146, -0.07002087],\n",
       "       [-0.78218146, -1.24637147],\n",
       "       [-0.51270866, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [-1.06127829,  1.10632974],\n",
       "       [-0.67631715, -0.07002087],\n",
       "       [-1.06127829, -1.24637147],\n",
       "       [-1.28263094,  1.10632974],\n",
       "       [-0.6955652 , -0.07002087],\n",
       "       [ 0.25721362, -0.07002087],\n",
       "       [-0.86879772,  1.10632974],\n",
       "       [-1.64834403, -0.07002087],\n",
       "       [-0.03150724,  1.10632974],\n",
       "       [-0.57045283,  1.10632974],\n",
       "       [-0.81105355,  1.10632974],\n",
       "       [-1.18639066,  1.10632974],\n",
       "       [-1.75420834,  1.10632974],\n",
       "       [-1.52323165, -1.24637147],\n",
       "       [ 1.23886453, -1.24637147],\n",
       "       [-0.18549169, -1.24637147],\n",
       "       [-0.5608288 , -1.24637147],\n",
       "       [-0.23361183,  1.10632974],\n",
       "       [ 1.68156984, -1.24637147],\n",
       "       [-0.4934606 , -0.07002087],\n",
       "       [-0.73406132, -1.24637147],\n",
       "       [ 0.85390339, -1.24637147],\n",
       "       [-0.67631715, -1.24637147],\n",
       "       [ 0.09360513,  1.10632974],\n",
       "       [ 0.33420585, -0.07002087],\n",
       "       [ 0.03586096, -0.07002087],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 1.04638396,  1.10632974],\n",
       "       [-0.65706909,  1.10632974],\n",
       "       [-0.13737155, -0.07002087],\n",
       "       [ 0.18984542,  1.10632974],\n",
       "       [ 0.04548499, -1.24637147],\n",
       "       [ 1.1618723 ,  1.10632974],\n",
       "       [-1.37887123, -1.24637147],\n",
       "       [ 1.39284898, -1.24637147],\n",
       "       [ 0.76728713, -0.07002087],\n",
       "       [-0.20473975, -0.07002087],\n",
       "       [ 1.06563201, -1.24637147],\n",
       "       [ 0.11285319, -1.24637147],\n",
       "       [ 1.28698467,  1.10632974],\n",
       "       [-0.41646838,  1.10632974],\n",
       "       [ 0.09360513, -1.24637147],\n",
       "       [ 0.59405462, -0.07002087],\n",
       "       [-2.03330517, -0.07002087],\n",
       "       [ 0.32458182, -1.24637147],\n",
       "       [ 0.40157405, -1.24637147],\n",
       "       [-1.10939843, -0.07002087],\n",
       "       [ 1.03675993, -1.24637147],\n",
       "       [-0.61857297, -0.07002087],\n",
       "       [ 0.44007016, -0.07002087],\n",
       "       [ 1.14262424, -1.24637147],\n",
       "       [-0.35872421,  1.10632974],\n",
       "       [ 0.45931822,  1.10632974],\n",
       "       [ 1.88367444,  1.10632974],\n",
       "       [ 0.45931822, -1.24637147],\n",
       "       [-0.12774752, -0.07002087],\n",
       "       [ 0.04548499,  1.10632974],\n",
       "       [ 0.85390339, -0.07002087],\n",
       "       [ 0.15134931, -0.07002087],\n",
       "       [ 0.8250313 ,  1.10632974],\n",
       "       [ 0.84427936,  1.10632974],\n",
       "       [-0.64744506, -1.24637147],\n",
       "       [ 1.24848856, -1.24637147],\n",
       "       [ 0.85390339,  1.10632974],\n",
       "       [ 1.69119387,  1.10632974],\n",
       "       [ 1.6334497 ,  1.10632974],\n",
       "       [ 1.46021718, -1.24637147],\n",
       "       [ 1.68156984, -0.07002087],\n",
       "       [-0.02188321,  1.10632974],\n",
       "       [ 0.87315144,  1.10632974],\n",
       "       [-0.33947615, -1.24637147],\n",
       "       [ 1.3639769 ,  1.10632974],\n",
       "       [ 1.12337618, -1.24637147],\n",
       "       [ 1.97029069, -0.07002087]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scaled\n",
    "#observe that new_data_scaled and x_scaled(using which we trained the model) looks the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.09051403, 3.26413803])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.predict(new_data_scaled)\n",
    "#so student1 gets a predicted GPA of 3.09 and student2--3.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##What if we removed the Rand 1,2,3 feature? As per the theory nothing should change.Try it out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
