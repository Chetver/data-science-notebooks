{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types of Clustering\n",
    "\n",
    "- Dendograms\n",
    "- KNN\n",
    "- Tree Methods\n",
    "    - Decision Tree\n",
    "    - Random Forrests\n",
    "- SVM (Support Vector Machine)\n",
    "- PCA (Principal Component Analysis)\n",
    "- NLP (Natural Lanuage Processing)\n",
    "\n",
    "Types of CLustering:\n",
    "- Flat\n",
    "    - Kmeans\n",
    "- Hieracheal\n",
    "    - Divisive:\n",
    "        - Top Down\n",
    "        - All of the observation are intially part of the same single cluster.\n",
    "        - Start: Vehicles -> Cars, Trucks. Cars -> Sports, Family, Compact etc\n",
    "    - Aggomerative\n",
    "        - Bottom Up\n",
    "        - Each observation is a cluster on its own. The goal being to start with many clusters and reduce the number of clusters.\n",
    "        - A Dendogram describes the 'map'/'structure' of the bottom up approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K Nearest Neighbour)\n",
    "*Classification Algorithm*\n",
    "\n",
    "Predicts the classification of a new datapoint by assessing it against the niehgbouring datapoints points.\n",
    "\n",
    "Steps:\n",
    "1. Calculate the distance of the new point from all other data points.\n",
    "2. Arrange the data points in increasing distance order of thier distance from the new point.\n",
    "3. Predict the majority label of the 'K' closest points.\n",
    "\n",
    "Start from a lower value of 'K' and systematically increment while continually assessing the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "\n",
    "- A single Decision Tree is not very accurate, this is addressed through the use of **Random Forrests** in which a new random sample of features is chosen for every single tree at every split.\n",
    "**Random Forrests**\n",
    "- It is possible to choose the feature on which a split will be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)\n",
    "\n",
    "SVM's use supervised learning models with associated learning algorithm that analyse data and  recognise patterns used for classification or regression analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Scalar:\n",
    "- One row, one column\n",
    "- 1 x 1\n",
    "- [99]\n",
    "\n",
    "Vectors:\n",
    "- [1 2 3]\n",
    "- Made up of scalars\n",
    "\n",
    "Matrix:\n",
    "- Made up of vectors\n",
    "\n",
    "Tensors:\n",
    "- Scalars are Rank 0 Tensor\n",
    "- Vectors are Rank 1 Tensor\n",
    "- Matrix are Rank 2 Tensor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "- Often used for text processing\n",
    "- **TF: Term Frequency**\n",
    "    - Importance of the term within the document.\n",
    "    - $TF(d,t)$ - Number of occurances of term '$t$' in document '$d$'\n",
    "- **IDF: Inverse Document Frequency**\n",
    "    - Importance of the term within the corpus (group) of documents.\n",
    "    - $IDF(t)=\\log(D/t)$, where:\n",
    "        - $D$ is the total number of documents\n",
    "        - $t$ is the number of documents with that term\n",
    "- $TF-IDF \\rightarrow W_{x,y} = tf_{x,y}\\times \\log(\\frac{N}{df_x})$\n",
    "    - where:\n",
    "        - $tf_{x,y}$ is the frequency of $x$ in $y$\n",
    "        - $df_x$ is the number of documents containing $x$\n",
    "        - $N$ is the total number of documents \n",
    "\n",
    "### PCA (Principal Component Analysis): Factor Analysis\n",
    "- The number of features in the data equals the number of dimensions\n",
    "- Used to make it easier to visualise data with many features (i.e 30) by displaying two components at a time.\n",
    "- Will always look for features which have the highest variance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Algorithm\n",
    "\n",
    "- Stemming\n",
    "    - Looks for the stem of a word, i.e. which letters are common between words.\n",
    "    - Can fail:\n",
    "        - **amus**e, **amus**sed, **amus**ement, **amus**sing\n",
    "- Lematisation\n",
    "    - The dictionary from or base form of a word.\n",
    "    - good -> better -> best\n",
    "        - better and best are surpurlative of 'good'\n",
    "        - a search for best will return results for better and good.\n",
    "\n",
    "Infelctional Form\n",
    "- Adding a suffix to a word **doesn't** change its gramatical category\n",
    "    - organise, organises, organised, organising (still a verb)\n",
    "Derrivinational From\n",
    "- Adding a suffix to a word **does** change its gramatical category\n",
    "- nation, national, nationalise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
